{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.layers import Input, Dense, Embedding, MaxPooling1D, Conv1D, SpatialDropout1D\n",
    "from keras.layers import add, Dropout, PReLU, BatchNormalization, GlobalMaxPooling1D, MaxPooling1D\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import Callback\n",
    "from keras import optimizers\n",
    "from keras import initializers, regularizers, constraints, callbacks\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import SVC, LinearSVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7380, 7)\n",
      "(2460, 2)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"TIL_NLP_train_dataset.csv\")\n",
    "test = pd.read_csv(\"TIL_NLP_test_dataset.csv\")\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>word_representation</th>\n",
       "      <th>outwear</th>\n",
       "      <th>top</th>\n",
       "      <th>trousers</th>\n",
       "      <th>women dresses</th>\n",
       "      <th>women skirts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>w7718 w173355 w138132 w232277 w90685 w314686 w...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>w195317 w127737 w171593 w22890 w342007 w217871...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>w247655 w270233 w261113 w337250 w366000 w37873...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                word_representation  outwear  top  \\\n",
       "0   0  w7718 w173355 w138132 w232277 w90685 w314686 w...        1    0   \n",
       "1   1  w195317 w127737 w171593 w22890 w342007 w217871...        1    0   \n",
       "2   2  w247655 w270233 w261113 w337250 w366000 w37873...        0    1   \n",
       "\n",
       "   trousers  women dresses  women skirts  \n",
       "0         1              0             0  \n",
       "1         1              0             0  \n",
       "2         1              0             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(3) ##Inpect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>word_representation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>w373517 w383437 w374393 w87179 w289496 w327385...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>w237465 w167111 w279437 w194870 w351537 w17560...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>w151648 w93366 w121255 w193800 w71240 w48576 w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                word_representation\n",
       "0   0  w373517 w383437 w374393 w87179 w289496 w327385...\n",
       "1   1  w237465 w167111 w279437 w194870 w351537 w17560...\n",
       "2   2  w151648 w93366 w121255 w193800 w71240 w48576 w..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(3) ##Inpect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract input and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    w7718 w173355 w138132 w232277 w90685 w314686 w...\n",
      "Name: word_representation, dtype: object\n",
      "   outwear  top  trousers  women dresses  women skirts\n",
      "0        1    0         1              0             0\n",
      "0    w373517 w383437 w374393 w87179 w289496 w327385...\n",
      "Name: word_representation, dtype: object\n"
     ]
    }
   ],
   "source": [
    "train_input = train[\"word_representation\"]\n",
    "train_labels = train[train.columns[2:]]\n",
    "test_input = test[\"word_representation\"]\n",
    "test_id = test[\"id\"]\n",
    "\n",
    "print(train_input.head(1))\n",
    "print(train_labels.head(1))\n",
    "print(test_input.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenise and pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6273, 82555)\n",
      "(1107, 82555)\n",
      "(6273, 5)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_input, train_labels, test_size=0.15, shuffle = True, random_state = 255)\n",
    "\n",
    "cvect = CountVectorizer(stop_words=\"english\", analyzer='word', \n",
    "                             ngram_range=(1, 6), max_df=1.0, min_df=1, max_features=None)\n",
    "cvect.fit(x_train)\n",
    "x_train_vectorized = cvect.transform(x_train)\n",
    "x_test_vectorized = cvect.transform(x_test)\n",
    "\n",
    "print(x_train_vectorized.shape)\n",
    "print(x_test_vectorized.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using CountVectorizer and LinearSVC: 0.9214092140921409\n"
     ]
    }
   ],
   "source": [
    "clf1 = LinearSVC(C=0.32, penalty=\"l2\")\n",
    "clf2 = LinearSVC(C=0.32, penalty=\"l2\")\n",
    "clf3 = LinearSVC(C=0.32, penalty=\"l2\")\n",
    "clf4 = LinearSVC(C=0.32, penalty=\"l2\")\n",
    "clf5 = LinearSVC(C=0.32, penalty=\"l2\")\n",
    "\n",
    "\"outwear\", \"top\", \"trousers\", \"women dresses\", \"women skirts\"\n",
    "clf1.fit(x_train_vectorized, y_train[\"outwear\"])\n",
    "clf2.fit(x_train_vectorized, y_train[\"top\"])\n",
    "clf3.fit(x_train_vectorized, y_train[\"trousers\"])\n",
    "clf4.fit(x_train_vectorized, y_train[\"women dresses\"])\n",
    "clf5.fit(x_train_vectorized, y_train[\"women skirts\"])\n",
    "\n",
    "\n",
    "y_pred1 = clf1.predict(x_test_vectorized)\n",
    "y_pred2 = clf2.predict(x_test_vectorized)\n",
    "y_pred3 = clf3.predict(x_test_vectorized)\n",
    "y_pred4 = clf4.predict(x_test_vectorized)\n",
    "y_pred5 = clf5.predict(x_test_vectorized)\n",
    "\n",
    "y_pred = np.stack((y_pred1,y_pred2,y_pred3, y_pred4, y_pred5), axis = 1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "print(\"Accuracy score using CountVectorizer and LinearSVC: {}\".format(accuracy_score(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using CountVectorizer and LinearSVC: 0.5338753387533876\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf1 = SGDClassifier(alpha = 0.2)\n",
    "clf2 = SGDClassifier(alpha = 0.2)\n",
    "clf3 = SGDClassifier(alpha = 0.2)\n",
    "clf4 = SGDClassifier(alpha = 0.2)\n",
    "clf5 = SGDClassifier(alpha = 0.2)\n",
    "\n",
    "\"outwear\", \"top\", \"trousers\", \"women dresses\", \"women skirts\"\n",
    "clf1.fit(x_train_vectorized, y_train[\"outwear\"])\n",
    "clf2.fit(x_train_vectorized, y_train[\"top\"])\n",
    "clf3.fit(x_train_vectorized, y_train[\"trousers\"])\n",
    "clf4.fit(x_train_vectorized, y_train[\"women dresses\"])\n",
    "clf5.fit(x_train_vectorized, y_train[\"women skirts\"])\n",
    "\n",
    "\n",
    "y_pred1 = clf1.predict(x_test_vectorized)\n",
    "y_pred2 = clf2.predict(x_test_vectorized)\n",
    "y_pred3 = clf3.predict(x_test_vectorized)\n",
    "y_pred4 = clf4.predict(x_test_vectorized)\n",
    "y_pred5 = clf5.predict(x_test_vectorized)\n",
    "\n",
    "y_pred = np.stack((y_pred1,y_pred2,y_pred3, y_pred4, y_pred5), axis = 1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "print(\"Accuracy score using CountVectorizer and SGD: {}\".format(accuracy_score(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score using CountVectorizer and SGD: 0.9024390243902439\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf1 = LogisticRegression(C=0.25, max_iter = 1000, solver = 'lbfgs')\n",
    "clf2 = LogisticRegression(C=0.25, max_iter = 1000, solver = 'lbfgs')\n",
    "clf3 = LogisticRegression(C=0.25, max_iter = 1000, solver = 'lbfgs')\n",
    "clf4 = LogisticRegression(C=0.25, max_iter = 1000, solver = 'lbfgs')\n",
    "clf5 = LogisticRegression(C=0.25, max_iter = 1000, solver = 'lbfgs')\n",
    "\n",
    "\"outwear\", \"top\", \"trousers\", \"women dresses\", \"women skirts\"\n",
    "clf1.fit(x_train_vectorized, y_train[\"outwear\"])\n",
    "clf2.fit(x_train_vectorized, y_train[\"top\"])\n",
    "clf3.fit(x_train_vectorized, y_train[\"trousers\"])\n",
    "clf4.fit(x_train_vectorized, y_train[\"women dresses\"])\n",
    "clf5.fit(x_train_vectorized, y_train[\"women skirts\"])\n",
    "\n",
    "\n",
    "y_pred1 = clf1.predict(x_test_vectorized)\n",
    "y_pred2 = clf2.predict(x_test_vectorized)\n",
    "y_pred3 = clf3.predict(x_test_vectorized)\n",
    "y_pred4 = clf4.predict(x_test_vectorized)\n",
    "y_pred5 = clf5.predict(x_test_vectorized)\n",
    "\n",
    "y_pred = np.stack((y_pred1,y_pred2,y_pred3, y_pred4, y_pred5), axis = 1)\n",
    "\n",
    "from sklearn.metrics import accuracy_score \n",
    "print(\"Accuracy score using CountVectorizer and SGD: {}\".format(accuracy_score(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer bidirectional is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 500]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-19769436440c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    201\u001b[0m       \u001b[1;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\layers\\wrappers.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBidirectional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    544\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m     \u001b[1;31m# Applies the same workaround as in `RNN.__call__`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    735\u001b[0m         \u001b[1;31m# are casted, not before.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m         input_spec.assert_input_compatibility(self.input_spec, inputs,\n\u001b[1;32m--> 737\u001b[1;33m                                               self.name)\n\u001b[0m\u001b[0;32m    738\u001b[0m         if (any(isinstance(x, ragged_tensor.RaggedTensor) for x in input_list)\n\u001b[0;32m    739\u001b[0m             and self._supports_ragged_inputs is False):  # pylint: disable=g-bool-id-comparison\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow_core\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    175\u001b[0m                          \u001b[1;34m'expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. Full shape received: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m                          str(x.shape.as_list()))\n\u001b[0m\u001b[0;32m    178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m       \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer bidirectional is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 500]"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 6), token_pattern=r'\\w{1,}', stop_words = None, min_df = 1)\n",
    "X_train_onehot = vectorizer.fit_transform(x_train)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=500, activation='relu', input_dim=len(vectorizer.get_feature_names())))\n",
    "model.add(Conv1D(512, 5, activation='relu'))\n",
    "model.add(Dropout(0.5)(x))\n",
    "\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    " \n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7380, 92095)\n",
      "(2460, 92095)\n",
      "(7380, 5)\n"
     ]
    }
   ],
   "source": [
    "cvect = CountVectorizer(stop_words=\"english\", analyzer='word', \n",
    "                             ngram_range=(1, 3), max_df=1.0, min_df=1, max_features=None)\n",
    "cvect.fit(train_input)\n",
    "x_train_vectorized = cvect.transform(train_input)\n",
    "x_test_vectorized = cvect.transform(test_input)\n",
    "\n",
    "print(x_train_vectorized.shape)\n",
    "print(x_test_vectorized.shape)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LinearSVC(C=0.32, penalty=\"l2\")\n",
    "clf2 = LinearSVC(C=0.32, penalty=\"l2\")\n",
    "clf3 = LinearSVC(C=0.32, penalty=\"l2\")\n",
    "clf4 = LinearSVC(C=0.32, penalty=\"l2\")\n",
    "clf5 = LinearSVC(C=0.32, penalty=\"l2\")\n",
    "\n",
    "## \"outwear\", \"top\", \"trousers\", \"women dresses\", \"women skirts\"\n",
    "clf1.fit(x_train_vectorized, train_labels[\"outwear\"])\n",
    "clf2.fit(x_train_vectorized, train_labels[\"top\"])\n",
    "clf3.fit(x_train_vectorized, train_labels[\"trousers\"])\n",
    "clf4.fit(x_train_vectorized, train_labels[\"women dresses\"])\n",
    "clf5.fit(x_train_vectorized, train_labels[\"women skirts\"])\n",
    "\n",
    "\n",
    "y_pred1 = clf1.predict(x_test_vectorized)\n",
    "y_pred2 = clf2.predict(x_test_vectorized)\n",
    "y_pred3 = clf3.predict(x_test_vectorized)\n",
    "y_pred4 = clf4.predict(x_test_vectorized)\n",
    "y_pred5 = clf5.predict(x_test_vectorized)\n",
    "\n",
    "y_pred = np.stack((y_pred1,y_pred2,y_pred3, y_pred4, y_pred5), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.DataFrame(y_pred, columns = [\"outwear\", \"top\", \"trousers\", \"women dresses\", \"women skirts\"])\n",
    "output = pd.concat([test_id , labels], axis = 1)\n",
    "output.head(3)\n",
    "output.to_csv('submission3.csv',index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
